{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCpLiUxIuCxJrQa+8cZMs9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgutierre/DataScience/blob/main/lab5_NLP_TextPrep_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Universidad EAFIT Maria jose Gutierrez Estrada 2024-2\n",
        "\n",
        "Se cargaron las librerias necesarias\n",
        "\n",
        "- nltk para 'procesamiento natural del lenguaje'\n",
        "- pandas para procesamiento de dataframes, muy usado en preparación de datos\n",
        "- re - expresiones regulares\n",
        "- numpy, codecs, etc - otras\n",
        "\n"
      ],
      "metadata": {
        "id": "vGs-mG2vcZwO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfL8lBipcJax",
        "outputId": "ca039f48-1c50-4bd5-e214-9d7b73e24ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=29e8bc3b340fe97c5534d3f19721a9e7ab4768ca7672ac1c544da5a22b72cf70\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# directorios (path) de entrada y salida:#\n",
        "path_in=\"../datasets/\"\n",
        "path_out=\"../out/\"\n",
        "filenametxt_in='in.txt'\n",
        "filenametxt_out='out.txt'\n",
        "filenamecsv_in='in.csv'\n",
        "filenamecsv_out='out.csv'"
      ],
      "metadata": {
        "id": "aw1uQFNlctk3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create spark session, no requerido en AWS EMR/Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('nlp').getOrCreate()"
      ],
      "metadata": {
        "id": "FU5lnL4jdIgw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame([(1,'I really liked this movie'),\n",
        "                         (2,'I would recommend this movie to my friends'),\n",
        "                         (3,'movie was alright but acting was horrible'),\n",
        "                         (4,'I am never watching that movie ever again')],\n",
        "                        ['user_id','review'])"
      ],
      "metadata": {
        "id": "OrVdYtT9dT75"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKl8MvNAdXCJ",
        "outputId": "68e3d42e-a66d-4e92-cc64-82461d1ed45e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------------------+\n",
            "|user_id|review                                    |\n",
            "+-------+------------------------------------------+\n",
            "|1      |I really liked this movie                 |\n",
            "|2      |I would recommend this movie to my friends|\n",
            "|3      |movie was alright but acting was horrible |\n",
            "|4      |I am never watching that movie ever again |\n",
            "+-------+------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n"
      ],
      "metadata": {
        "id": "NwRG5pFGdaTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer"
      ],
      "metadata": {
        "id": "L-sl1byNdZvv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenization=Tokenizer(inputCol='review',outputCol='tokens')"
      ],
      "metadata": {
        "id": "u83X1aaqdfwn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_df=tokenization.transform(df)"
      ],
      "metadata": {
        "id": "Ro4_SCwHdh6e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_df.show(4,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0aYDYMYdkKw",
        "outputId": "2c30b2cc-ef60-4c56-e740-621dba85fda8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------------------+---------------------------------------------------+\n",
            "|user_id|review                                    |tokens                                             |\n",
            "+-------+------------------------------------------+---------------------------------------------------+\n",
            "|1      |I really liked this movie                 |[i, really, liked, this, movie]                    |\n",
            "|2      |I would recommend this movie to my friends|[i, would, recommend, this, movie, to, my, friends]|\n",
            "|3      |movie was alright but acting was horrible |[movie, was, alright, but, acting, was, horrible]  |\n",
            "|4      |I am never watching that movie ever again |[i, am, never, watching, that, movie, ever, again] |\n",
            "+-------+------------------------------------------+---------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords removal\n"
      ],
      "metadata": {
        "id": "H73QTnwceYKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StopWordsRemover"
      ],
      "metadata": {
        "id": "BfJZAHIqdlhY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')"
      ],
      "metadata": {
        "id": "53eL5NLMec49"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refined_df=stopword_removal.transform(tokenized_df)"
      ],
      "metadata": {
        "id": "8mhO4zaIeexh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refined_df.select(['user_id','tokens','refined_tokens']).show(10,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP7-3EUNeg14",
        "outputId": "191a73a9-2798-43b8-84e2-c779e19a6ea0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------------------------------------------------+----------------------------------+\n",
            "|user_id|tokens                                             |refined_tokens                    |\n",
            "+-------+---------------------------------------------------+----------------------------------+\n",
            "|1      |[i, really, liked, this, movie]                    |[really, liked, movie]            |\n",
            "|2      |[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |\n",
            "|3      |[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|\n",
            "|4      |[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |\n",
            "+-------+---------------------------------------------------+----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movies reviews\n"
      ],
      "metadata": {
        "id": "sieOuuHBekuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_df=spark.read.csv('sample_data/movie_reviews.csv',inferSchema=True,header=True,sep=',')\n",
        "# datos desde S3"
      ],
      "metadata": {
        "id": "HteSfL4Pekgy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1yfXCk2f5PX",
        "outputId": "503d41b3-847b-4444-ea6a-649e00992c02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Review: string (nullable = true)\n",
            " |-- Sentiment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezzBjb4Sf71b",
        "outputId": "8da2c1f6-e2b9-448a-b88c-bab1ae421b33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7087"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning\n"
      ],
      "metadata": {
        "id": "wmeX1cG4f-dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenization=Tokenizer(inputCol='Review',outputCol='tokens')"
      ],
      "metadata": {
        "id": "s1gUlQIWgAY5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_df=tokenization.transform(text_df)"
      ],
      "metadata": {
        "id": "tDKkuXOVgEJ3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2B_ltVogGLY",
        "outputId": "a9318e92-eaf9-4689-e1b9-26b5a7c5bf4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+\n",
            "|              Review|Sentiment|              tokens|\n",
            "+--------------------+---------+--------------------+\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|\n",
            "|this was the firs...|        1|[this, was, the, ...|\n",
            "|i liked the Da Vi...|        1|[i, liked, the, d...|\n",
            "|i liked the Da Vi...|        1|[i, liked, the, d...|\n",
            "|I liked the Da Vi...|        1|[i, liked, the, d...|\n",
            "|that's not even a...|        1|[that's, not, eve...|\n",
            "|I loved the Da Vi...|        1|[i, loved, the, d...|\n",
            "|i thought da vinc...|        1|[i, thought, da, ...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|\n",
            "|I thought the Da ...|        1|[i, thought, the,...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|\n",
            "|then I turn on th...|        1|[then, i, turn, o...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|\n",
            "|i love da vinci c...|        1|[i, love, da, vin...|\n",
            "|i loved da vinci ...|        1|[i, loved, da, vi...|\n",
            "|TO NIGHT:: THE DA...|        1|[to, night::, the...|\n",
            "|THE DA VINCI CODE...|        1|[the, da, vinci, ...|\n",
            "|Thing is, I enjoy...|        1|[thing, is,, i, e...|\n",
            "|very da vinci cod...|        1|[very, da, vinci,...|\n",
            "+--------------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')"
      ],
      "metadata": {
        "id": "FZ6xMcMOgHtU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refined_text_df=stopword_removal.transform(tokenized_df)"
      ],
      "metadata": {
        "id": "50_snbAKgLSk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refined_text_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoWJs1sHgNGL",
        "outputId": "d8b9a8e8-cf67-4cc4-84b5-dab807f82728"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+--------------------+\n",
            "|              Review|Sentiment|              tokens|      refined_tokens|\n",
            "+--------------------+---------+--------------------+--------------------+\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|this was the firs...|        1|[this, was, the, ...|[first, clive, cu...|\n",
            "|i liked the Da Vi...|        1|[i, liked, the, d...|[liked, da, vinci...|\n",
            "|i liked the Da Vi...|        1|[i, liked, the, d...|[liked, da, vinci...|\n",
            "|I liked the Da Vi...|        1|[i, liked, the, d...|[liked, da, vinci...|\n",
            "|that's not even a...|        1|[that's, not, eve...|[even, exaggerati...|\n",
            "|I loved the Da Vi...|        1|[i, loved, the, d...|[loved, da, vinci...|\n",
            "|i thought da vinc...|        1|[i, thought, da, ...|[thought, da, vin...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|I thought the Da ...|        1|[i, thought, the,...|[thought, da, vin...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|then I turn on th...|        1|[then, i, turn, o...|[turn, light, rad...|\n",
            "|The Da Vinci Code...|        1|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|i love da vinci c...|        1|[i, love, da, vin...|[love, da, vinci,...|\n",
            "|i loved da vinci ...|        1|[i, loved, da, vi...|[loved, da, vinci...|\n",
            "|TO NIGHT:: THE DA...|        1|[to, night::, the...|[night::, da, vin...|\n",
            "|THE DA VINCI CODE...|        1|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|Thing is, I enjoy...|        1|[thing, is,, i, e...|[thing, is,, enjo...|\n",
            "|very da vinci cod...|        1|[very, da, vinci,...|[da, vinci, code,...|\n",
            "+--------------------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "y8iV5BWugORw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "\n",
        "refined_text_df = refined_text_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))"
      ],
      "metadata": {
        "id": "ZXHibJxsgR5a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refined_text_df.orderBy(rand()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySZYGTfggTrY",
        "outputId": "1f2ce006-6047-432f-d898-ebf5bc3b1f43"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+--------------------+-----------+\n",
            "|              Review|Sentiment|              tokens|      refined_tokens|token_count|\n",
            "+--------------------+---------+--------------------+--------------------+-----------+\n",
            "|I hate Harry Potter.|        0|[i, hate, harry, ...|[hate, harry, pot...|          3|\n",
            "|Its freezing cold...|        0|[its, freezing, c...|[freezing, cold, ...|          7|\n",
            "|\"Anyway, thats wh...|        1|[\"anyway,, thats,...|[\"anyway,, thats,...|          6|\n",
            "|Brokeback Mountai...|        0|[brokeback, mount...|[brokeback, mount...|          4|\n",
            "|Brokeback Mountai...|        1|[brokeback, mount...|[brokeback, mount...|          4|\n",
            "|I love The Da Vin...|        1|[i, love, the, da...|[love, da, vinci,...|          4|\n",
            "|I love Brokeback ...|        1|[i, love, brokeba...|[love, brokeback,...|          3|\n",
            "|Harry Potter drag...|        0|[harry, potter, d...|[harry, potter, d...|          9|\n",
            "|I want to be here...|        1|[i, want, to, be,...|[want, love, harr...|          7|\n",
            "|So as felicia's m...|        1|[so, as, felicia'...|[felicia's, mom, ...|          7|\n",
            "+--------------------+---------+--------------------+--------------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert the 'refined_tokens' column to a string representation\n",
        "refined_text_df = refined_text_df.withColumn(\"refined_tokens\", col(\"refined_tokens\").cast(\"string\"))\n",
        "\n",
        "# Add the mode(\"overwrite\") to the write command\n",
        "refined_text_df.coalesce(1).write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\").save('.../Out/out.csv')"
      ],
      "metadata": {
        "id": "WpG5iPA6gVYf"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}