{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtjgo4V3VL8iPUO2YWdfWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgutierre/DataScience/blob/main/lab7_NLP_PySpark_bow_tf_idf_google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Universidad EAFIT Maria jose Gutierrez Estrada 2024-2\n",
        "\n",
        "Se cargaron las librerias necesarias\n",
        "\n",
        "- nltk para 'procesamiento natural del lenguaje'\n",
        "- pandas para procesamiento de dataframes, muy usado en preparaci贸n de datos\n",
        "- re - expresiones regulares\n",
        "- numpy, codecs, etc - otras\n"
      ],
      "metadata": {
        "id": "o_41M2griGrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEypMCfWh-CP",
        "outputId": "30418194-2861-4a9f-fe8e-739be8b335f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#configuraci贸n en google colab de spark y pyspark\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instalar java y spark\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.2-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "-MeC5rKHiNkw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#forma 1 de crear la sesi贸n y el contexto Spark:\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "2Nxd-NoyiPw7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext # import SparkContext\n",
        "\n",
        "#forma 2 de crear la sesi贸n y el contexto Spark:\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark=SparkSession.builder.appName('nlp').getOrCreate()"
      ],
      "metadata": {
        "id": "i0hu-7kTkJqf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame([(1,'I really liked this movie'),\n",
        "                         (2,'I would recommend this movie to my friends'),\n",
        "                         (3,'movie was alright but acting was horrible'),\n",
        "                         (4,'I am never watching that movie ever again')],\n",
        "                        ['user_id','content'])"
      ],
      "metadata": {
        "id": "jmlgRqtwkg2T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr7Wyc0Ikks9",
        "outputId": "ffefe9e7-4101-4086-ee40-29677813cd85"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- content: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n"
      ],
      "metadata": {
        "id": "S-GDizkNkqGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "tokenization=Tokenizer(inputCol='content',outputCol='tokens')\n",
        "tokenized_df=tokenization.transform(df)\n",
        "tokenized_df.printSchema()\n",
        "tokenized_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syox18ltkltl",
        "outputId": "c6ae63ce-69e7-4c21-df1f-b09e8fd633e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- content: string (nullable = true)\n",
            " |-- tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|\n",
            "|      2|I would recommend...|[i, would, recomm...|\n",
            "|      3|movie was alright...|[movie, was, alri...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|\n",
            "+-------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords removal\n"
      ],
      "metadata": {
        "id": "6FrcBprqkty_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n",
        "refined_df=stopword_removal.transform(tokenized_df)\n",
        "refined_df.select(['tokens','refined_tokens']).show(10,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy4L2h_kkvJP",
        "outputId": "7bb0dbcf-3480-44f9-91cf-b955ca646bec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+----------------------------------+\n",
            "|tokens                                             |refined_tokens                    |\n",
            "+---------------------------------------------------+----------------------------------+\n",
            "|[i, really, liked, this, movie]                    |[really, liked, movie]            |\n",
            "|[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |\n",
            "|[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|\n",
            "|[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |\n",
            "+---------------------------------------------------+----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refined_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnhog5NWkzTK",
        "outputId": "df3109d5-c23d-4fe0-e761-d197d8e1f8f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user_id', 'content', 'tokens', 'refined_tokens']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "dgMxKUGLk1Yr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "\n",
        "refined_count_df = refined_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))"
      ],
      "metadata": {
        "id": "a36D7nuik3ng"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refined_count_df.orderBy(rand()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLKcH_Snk_1e",
        "outputId": "45d3983c-95df-4b29-ba98-0f0cce9beca9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "|user_id|             content|              tokens|      refined_tokens|token_count|\n",
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|          3|\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|          3|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|          4|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|          4|\n",
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count Vectorizer\n"
      ],
      "metadata": {
        "id": "1yoDFNv_lFbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
        "cv_df=count_vec.fit(refined_df).transform(refined_df)\n",
        "cv_df.select(['refined_tokens','features']).show(4,False)\n",
        "bow = count_vec.fit(refined_df).vocabulary\n",
        "print(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BhAI3nwlBe3",
        "outputId": "2ceb0421-5d5a-49ed-877f-5b9a4a73215e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+--------------------------------+\n",
            "|refined_tokens                    |features                        |\n",
            "+----------------------------------+--------------------------------+\n",
            "|[really, liked, movie]            |(11,[0,3,5],[1.0,1.0,1.0])      |\n",
            "|[recommend, movie, friends]       |(11,[0,2,10],[1.0,1.0,1.0])     |\n",
            "|[movie, alright, acting, horrible]|(11,[0,1,8,9],[1.0,1.0,1.0,1.0])|\n",
            "|[never, watching, movie, ever]    |(11,[0,4,6,7],[1.0,1.0,1.0,1.0])|\n",
            "+----------------------------------+--------------------------------+\n",
            "\n",
            "['movie', 'horrible', 'recommend', 'liked', 'never', 'really', 'ever', 'watching', 'acting', 'alright', 'friends']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF with HashingTF (Con y sin numFeatures)\n"
      ],
      "metadata": {
        "id": "gQ9z17LUlOpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF\n",
        "\n",
        "l = len(bow)\n",
        "hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=l)\n",
        "\n",
        "\n",
        "hashing_df=hashing_vec.transform(refined_df)\n",
        "hashing_df.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybF72kX_lJCg",
        "outputId": "da42beef-2875-4f03-ac11-d669f4012cf3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|      refined_tokens|         tf_features|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|(11,[9,10],[2.0,1...|\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|(11,[1,6,9],[1.0,...|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|(11,[1,6,9,10],[1...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|(11,[0,7,8,9],[1....|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF\n",
        "\n",
        "l = len(bow)\n",
        "#hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=l)\n",
        "hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=11)\n",
        "\n",
        "# compare la salida e interprete con y sin numFeatures:\n",
        "hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features')\n",
        "\n",
        "hashing_df=hashing_vec.transform(refined_df)\n",
        "hashing_df.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_aLFiYdlSh5",
        "outputId": "496ec2dc-92c0-4860-9ce6-b474a1e45d02"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|      refined_tokens|         tf_features|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|(262144,[99172,21...|\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|(262144,[68228,13...|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|(262144,[95685,17...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|(262144,[63139,11...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "tf_idf_vec=IDF(inputCol='tf_features',outputCol='tf_idf_features')\n",
        "tf_idf_df=tf_idf_vec.fit(hashing_df).transform(hashing_df)\n",
        "tf_idf_df.show(4,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yngZRCKclz7L",
        "outputId": "8b531166-e8b2-4a85-c179-a7f1ae8625e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "|user_id|content                                   |tokens                                             |refined_tokens                    |tf_features                      |tf_idf_features                                                               |\n",
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "|1      |I really liked this movie                 |[i, really, liked, this, movie]                    |[really, liked, movie]            |(11,[9,10],[2.0,1.0])            |(11,[9,10],[0.0,0.5108256237659907])                                          |\n",
            "|2      |I would recommend this movie to my friends|[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |(11,[1,6,9],[1.0,1.0,1.0])       |(11,[1,6,9],[0.5108256237659907,0.5108256237659907,0.0])                      |\n",
            "|3      |movie was alright but acting was horrible |[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|(11,[1,6,9,10],[1.0,1.0,1.0,1.0])|(11,[1,6,9,10],[0.5108256237659907,0.5108256237659907,0.0,0.5108256237659907])|\n",
            "|4      |I am never watching that movie ever again |[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |(11,[0,7,8,9],[1.0,1.0,1.0,1.0]) |(11,[0,7,8,9],[0.9162907318741551,0.9162907318741551,0.9162907318741551,0.0]) |\n",
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}